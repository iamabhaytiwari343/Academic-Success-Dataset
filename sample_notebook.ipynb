{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: ['cat', 'dog', 'fish', 'dog', 'cat']\n",
      "Encoded data: [0 1 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "data = ['cat', 'dog', 'fish', 'dog', 'cat']\n",
    "le = LabelEncoder()\n",
    "le.fit(data)\n",
    "encoded_data = le.transform(data)\n",
    "print(\"Original data:\", data)\n",
    "print(\"Encoded data:\", encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: [['cat'], ['dog'], ['fish'], ['dog'], ['cat']]\n",
      "Encoded data: [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "data = [['cat'], ['dog'], ['fish'], ['dog'], ['cat']]\n",
    "encoder = OneHotEncoder(sparse=False)  \n",
    "encoder.fit(data)\n",
    "encoded_data = encoder.transform(data)\n",
    "print(\"Original data:\", data)\n",
    "print(\"Encoded data:\", encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: [['low'], ['low'], ['medium'], ['medium'], ['high'], ['low'], ['medium'], ['high'], ['low']]\n",
      "Encoded data: [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "data = [['low'], ['low'], ['medium'], ['medium'], ['high'], ['low'], ['medium'], ['high'], ['low']]\n",
    "categories = [['low', 'medium', 'high']] \n",
    "encoder = OrdinalEncoder(categories=categories)  \n",
    "encoder.fit(data)\n",
    "encoded_data = encoder.transform(data)\n",
    "print(\"Original data:\", data)\n",
    "print(\"Encoded data:\", encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: ['cat', 'dog', 'fish', 'dog', 'cat']\n",
      "Encoded data: [[1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "def binary_encode(data, categories):\n",
    "  num_categories = len(categories)\n",
    "  encoded_data = []\n",
    "  for item in data:\n",
    "    binary_vector = [0] * num_categories  \n",
    "    if item in categories:\n",
    "      index = categories.index(item)\n",
    "      binary_vector[index] = 1  \n",
    "    encoded_data.append(binary_vector)\n",
    "  return encoded_data\n",
    "data = ['cat', 'dog', 'fish', 'dog', 'cat']\n",
    "categories = ['cat', 'dog', 'fish']\n",
    "encoded_data = binary_encode(data, categories)\n",
    "print(\"Original data:\", data)\n",
    "print(\"Encoded data:\", encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:   category\n",
      "0        A\n",
      "1        A\n",
      "2        B\n",
      "3        B\n",
      "4        A\n",
      "5        C\n",
      "Encoded data:    category\n",
      "0  0.500000\n",
      "1  0.500000\n",
      "2  0.333333\n",
      "3  0.333333\n",
      "4  0.500000\n",
      "5  0.166667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def frequency_encode(data, column):\n",
    "  value_counts = data[column].value_counts(normalize=True)\n",
    "  encoded_data = data.copy()\n",
    "  encoded_data[column] = encoded_data[column].map(value_counts)\n",
    "  return encoded_data\n",
    "data = pd.DataFrame({'category': ['A', 'A', 'B', 'B', 'A', 'C']})\n",
    "encoded_data = frequency_encode(data.copy(), 'category')\n",
    "print(\"Original data:\", data)\n",
    "print(\"Encoded data:\", encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: [[10.0], [2.0], [7.0], [4.0], [12.0]]\n",
      "Scaled data: [[ 0.81348922]\n",
      " [-1.35581536]\n",
      " [ 0.        ]\n",
      " [-0.81348922]\n",
      " [ 1.35581536]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[10.0], [2.0], [7.0], [4.0], [12.0]]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "scaled_data = scaler.transform(data)\n",
    "print(\"Original data:\", data)\n",
    "print(\"Scaled data:\", scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "[[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
      "\n",
      "Scaled data:\n",
      "[[0.   0.  ]\n",
      " [0.25 0.25]\n",
      " [0.5  0.5 ]\n",
      " [1.   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Sample data\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    "\n",
    "# Create the MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the data (learn min and max for each feature)\n",
    "scaler.fit(data)\n",
    "\n",
    "# Transform the data (scale to 0-1 range by default)\n",
    "scaled_data = scaler.transform(data)\n",
    "\n",
    "# Print the original and scaled data\n",
    "print(\"Original data:\")\n",
    "print(data)\n",
    "print(\"\\nScaled data:\")\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "[[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
      "\n",
      "Scaled data:\n",
      "[[-0.85714286 -0.85714286]\n",
      " [-0.28571429 -0.28571429]\n",
      " [ 0.28571429  0.28571429]\n",
      " [ 1.42857143  1.42857143]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Sample data\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    "\n",
    "# Create the RobustScaler object\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit the scaler on the data (learn median and IQR for each feature)\n",
    "scaler.fit(data)\n",
    "\n",
    "# Transform the data (scale using median and IQR)\n",
    "scaled_data = scaler.transform(data)\n",
    "\n",
    "# Print the original and scaled data\n",
    "print(\"Original data:\")\n",
    "print(data)\n",
    "print(\"\\nScaled data:\")\n",
    "print(scaled_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [2. 2.]\n",
      "Intercept: -0.9999999999999991\n",
      "Prediction for [3, 5]: [15.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Sample data\n",
    "X = [[1, 1], [1, 2], [2, 2], [2, 3]]\n",
    "y = [3, 5, 7, 9]\n",
    "\n",
    "# Create the LinearRegression object\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the data (learn coefficients)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict([[3, 5]])\n",
    "\n",
    "# Print the coefficients and prediction\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Prediction for [3, 5]:\", y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: [1]\n",
      "Probabilities: [[0.36125603 0.63874397]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Sample data (binary classification)\n",
    "X = [[1, 1], [1.5, 1.8], [5, 8], [8, 8.5]]\n",
    "y = [0, 1, 1, 0]\n",
    "\n",
    "# Create the LogisticRegression object\n",
    "model = LogisticRegression(random_state=0)  # Set random_state for reproducibility\n",
    "\n",
    "# Fit the model on the data (learn weights and bias)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict([[3, 5]])\n",
    "y_proba = model.predict_proba([[3, 5]])  # Get probability of each class\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predicted class:\", y_pred)\n",
    "print(\"Probabilities:\", y_proba)  # Probability of class 0 and 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
