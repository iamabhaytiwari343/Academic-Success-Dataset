{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: ['cat', 'dog', 'fish', 'dog', 'cat']\n",
      "Encoded data: [0 1 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "data = ['cat', 'dog', 'fish', 'dog', 'cat']\n",
    "le = LabelEncoder()\n",
    "le.fit(data)\n",
    "encoded_data = le.transform(data)\n",
    "print(\"Original data:\", data)\n",
    "print(\"Encoded data:\", encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: [['cat'], ['dog'], ['fish'], ['dog'], ['cat']]\n",
      "Encoded data: [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "data = [['cat'], ['dog'], ['fish'], ['dog'], ['cat']]\n",
    "encoder = OneHotEncoder(sparse=False)  \n",
    "encoder.fit(data)\n",
    "encoded_data = encoder.transform(data)\n",
    "print(\"Original data:\", data)\n",
    "print(\"Encoded data:\", encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: [['low'], ['low'], ['medium'], ['medium'], ['high'], ['low'], ['medium'], ['high'], ['low']]\n",
      "Encoded data: [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "data = [['low'], ['low'], ['medium'], ['medium'], ['high'], ['low'], ['medium'], ['high'], ['low']]\n",
    "categories = [['low', 'medium', 'high']] \n",
    "encoder = OrdinalEncoder(categories=categories)  \n",
    "encoder.fit(data)\n",
    "encoded_data = encoder.transform(data)\n",
    "print(\"Original data:\", data)\n",
    "print(\"Encoded data:\", encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: ['cat', 'dog', 'fish', 'dog', 'cat']\n",
      "Encoded data: [[1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "def binary_encode(data, categories):\n",
    "  num_categories = len(categories)\n",
    "  encoded_data = []\n",
    "  for item in data:\n",
    "    binary_vector = [0] * num_categories  \n",
    "    if item in categories:\n",
    "      index = categories.index(item)\n",
    "      binary_vector[index] = 1  \n",
    "    encoded_data.append(binary_vector)\n",
    "  return encoded_data\n",
    "data = ['cat', 'dog', 'fish', 'dog', 'cat']\n",
    "categories = ['cat', 'dog', 'fish']\n",
    "encoded_data = binary_encode(data, categories)\n",
    "print(\"Original data:\", data)\n",
    "print(\"Encoded data:\", encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:   category\n",
      "0        A\n",
      "1        A\n",
      "2        B\n",
      "3        B\n",
      "4        A\n",
      "5        C\n",
      "Encoded data:    category\n",
      "0  0.500000\n",
      "1  0.500000\n",
      "2  0.333333\n",
      "3  0.333333\n",
      "4  0.500000\n",
      "5  0.166667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def frequency_encode(data, column):\n",
    "  value_counts = data[column].value_counts(normalize=True)\n",
    "  encoded_data = data.copy()\n",
    "  encoded_data[column] = encoded_data[column].map(value_counts)\n",
    "  return encoded_data\n",
    "data = pd.DataFrame({'category': ['A', 'A', 'B', 'B', 'A', 'C']})\n",
    "encoded_data = frequency_encode(data.copy(), 'category')\n",
    "print(\"Original data:\", data)\n",
    "print(\"Encoded data:\", encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: [[10.0], [2.0], [7.0], [4.0], [12.0]]\n",
      "Scaled data: [[ 0.81348922]\n",
      " [-1.35581536]\n",
      " [ 0.        ]\n",
      " [-0.81348922]\n",
      " [ 1.35581536]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[10.0], [2.0], [7.0], [4.0], [12.0]]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "scaled_data = scaler.transform(data)\n",
    "print(\"Original data:\", data)\n",
    "print(\"Scaled data:\", scaled_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
